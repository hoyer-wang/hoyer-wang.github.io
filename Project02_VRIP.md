<h3>Virtual Reality Integration Platform</h3>

<p style="text-align:justify">Designing experimental equipment with intelligence in a virtual reality lab classroom is an interesting task. This project is oriented to the virtual chemistry experiment classroom, using 3D printing technology and multi-sensor fusion technology to design intelligent experimental equipment such as smart beakers and smart experiment platforms to meet the purpose of detecting the user's action behavior of dumping and moving chemical experiment equipment. Meanwhile, we use various technologies such as deep learning technology, YOLOv5 object recognition technology, and multimodal fusion technology to design a user experiment intention understanding algorithm based on multi-channel information fusion for obtaining user's experiment intention and guiding or correcting user's behavior.</p>

<img src="/assets/img/vrip03.png">

<p style="text-align:justify"><b>The intelligent sensing capability of the experiment platform</b> can detect the user's action of picking up and putting back the chemical experiment equipment, as well as the detection of the experiment instrument category.</p>

<img src="/assets/img/vrip04.png">

<img src="/assets/img/vrip01.png">


<p style="text-align:justify">For the application scenario of virtual laboratory classroom, the structure of intelligent beaker device with the function of sensing user behavior is designed.</p>

1. **Smart large beaker** packs light sensors, touch sensors as well as a temperature change sensing chip, with different sensors used to detect different behaviors of the user.

<img src="/assets/img/vrip05.png">


2. **Smart Small Beaker** has a built-in attitude sensor (located on the inside of the small beaker to detect the direction and speed of the beaker's pour) and an infrared sensor (to detect the distance between the small beaker and the large beaker).



3. <p style="text-align:justify">The binocular camera is fixed in the wrist portion of the smart glove, which not only allows for real-time information gathering about the experimental scene, but also addresses the issues with obscuration and poor long-distance object recognition accuracy. It is frequently brought on by the traditional virtual experiment practice of using cameras and KINECT devices. The smart glove's binocular camera and sensor group transfer sensing data and visual data to the computer through Bluetooth and USB, respectively. Figure 3 illustrates the hardware structure of this system.</p>

<img src="/assets/img/mrsg03.png">
